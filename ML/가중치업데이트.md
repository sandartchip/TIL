

- 모델이 데이터를 입력 받아 층별로 계산한 뒤 "예측" 값을 내놓는 과정을 **순전파(forward propagation)** 라고 한다.
- Forward Propagation으로 생성된  **그 예측(score)** 과 정답과의 거리를 계산하고 평균을 내 "비용(Loss)"을 계산한 후, 모델이 더 좋은 예측을 할 수 있는 방향으로 가중치 업데이트 = 역전파

<img src="https://github.com/sandartchip/TIL/assets/15938354/0d87fe0b-884d-4b6b-aabc-04c891798e15" width="600px" />

- Loss: 예측과 정답 간의 거리 


#### 가중치 업데이트 
- 가중치의 기존 값에서 학습률과 기울기를 곱한 값을 뺌

<img src="https://github.com/sandartchip/TIL/assets/15938354/ba08d2b9-1185-4ce0-a3e0-189702226352" width="300px" />

<br>

<img src="https://github.com/sandartchip/TIL/assets/15938354/32c47781-8b5c-43c9-b182-3c035863a2fc" width="250px" />


- 수식은 복잡하게 전개 됬지만 Gradient를 구하기가 매우 쉽고, 이렇게 구한 gradient 또한 0으로 죽는 일이 많지 않아서 Softmax + Cross Entropy가 

https://www.philgineer.com/2021/09/27-5.html
