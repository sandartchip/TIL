## 가중치의 초기화
```python
class Custom_Net(nn.Module):
   def __init_(self):
     super(Custom_Net, self).__init__()

     self.linear_1 = nn.Linear(1024, 1024, bias=False)
     self.linear_2 = nn.Lienar(1024, 512, bias=False)
     self.linear_3 = nn.Linear(512, 10, bias=True)

     torch.nn.init.constant_(self.linear_1.weight.data, 0)
     torch.nn.init.uniform_(self.linear_2.weight.data)
     torch.nn.init.xavier_normal_(self.linear_3.weight.data)
     torch.nn.init.xavier_normal_(self.linear_3.bias.data)

  def forward(self, x):   
     ...
```


#### 입력 텐서를 값으로 채움
```python
torch.nn.init.constant_(tensor, val)
```  

```python
 w = torch.empty(3, 5)
 nn.init.constant_(w, 0.3)
```

#### input tensor를 uniform distribution(a, b 범위에서 모든 값이 균일한 분포)로 초기화
```python
nn.init.uniform_(input, a=0.0, b=0.1)
```

#### input tensor가 He 초기값을 N(0, std^2)의 정규분포를 갖는다

![image](https://github.com/sandartchip/TIL/assets/15938354/ed503852-4ffa-4770-a075-74597b2c59a4)

```python
nn.init.kaiming_normal_(input, mode='fan_in', nonlinearity='relu')
```


#### 출처 
https://velog.io/@khs0415p/Pytorch-initializer-%EC%A0%95%EB%A6%AC
