
#### TORCH.AUTOGRAD

- 신경망을 학습할 때 가장 자주 사용되는 알고리즘은 역전파이다.
- 이 알고리즘에서, 매개변수(모델 가중치)는 주어진 매개변수에 대한 손실 함수의 변화도(gradient)에 따라 조정된다.

- 이러한 변화도를 계산하기 위해, PyTorch에서는 torch.autograd라고 불리는 자동미분 엔진이 내장되어 있다.
- 이는 모든 계산 그래프에 대한 변화도의 자동 계산을 지원한다.

- 입력 x, 매개변수 w와 b, 그리고 일부 손실함수가 있는 가장 간단한 단일 계층 신경망을 가정.

#### torch.autograd.Variable 

![image](https://user-images.githubusercontent.com/15938354/175445588-41a03218-e6ab-4ba4-b5c6-774c64ed0c60.png)

- Variable 클래스는, 각 tensor의 값을 볼 수 있는 data, 미분을 보는 grad, backward를 통한 미분을 계산한 함수 정보인 grad_fn 총 3개의 함수를 사용 가능.

- 즉, loss의 backward()를 통해 backpropagation을 구하고 이를 통해 weight들을 자신의 데이터에 맞게 변화시킴
- 
