


## 최종 목적 


1) 주어진 입력값에 상관없이, 임의의 초기 가중치(w)를 준 뒤 은닉층을 거쳐 결과를 계산합니다.

2) 계산 결과와 실제 예측하고자 하는 값 사이의 오차를 구합니다.

3) 가중치를 업데이트 합니다.

4) '1~3'의 과정을 오차가 더이상 줄어들지 않을 때까지 반복합니다.



- 나의 목표 target값과 실제 모델이 예측한 output이 얼마나 차이나는지 구한 후, 오차값을 다시 뒤로 전파해가며 변수들을 갱신하는 알고리즘. 
- Gradient Descent를 이용해 가중치 갱신을 해야 하고, Gradient Desc를 하기 위해선 Loss Function의 Gradient가 필요한데, 
그 Loss function의 gradient를 backpropagatin으로 전달 받는다. 


### Gradient Descent 

![image](https://user-images.githubusercontent.com/15938354/179878036-79a2768d-b2e2-4a61-a5ec-e95fd4952665.png)
- 한발 내려간 시점에서, 등산객이 자기가 산을 제대로 내려가고 있는지 주변 경사(기울기)를 보면서 판단하듯이, 기울기가 음수인지 양수인지 확인하면서 최저지점으로 내려감.

### epoch 
- 한 번의 epoch은, 인공 신경망에서 전체 데이터셋에 대해 forward/backward pass 과정을 한 번 거친 것을 말함. 
- 1번의 epoch는, 전체 데이터셋에 대해 한 번의 학습 과정이 완료됬다고 이해하면 왼다. 
- epoch를 늘릴 수록, 가중치가 계속 
- epoch 값이 너무 작다면 underfitting, 너무 크면 overfitting 



## 과정
- 가중치 갱신을 위해서, 필요한 loss function의 gradient를 chain Rule을 이용해 앞으로 전달해주는 알고리즘 
- 


https://bskyvision.com/718 <br>
https://m.blog.naver.com/qbxlvnf11/221449297033
