

## 최종 목적 


1) 주어진 입력값에 상관없이, 임의의 초기 가중치(w)를 준 뒤 은닉층을 거쳐 결과를 계산합니다.

2) 계산 결과와 실제 예측하고자 하는 값 사이의 오차를 구합니다.

3) 가중치를 업데이트 합니다.

4) '1~3'의 과정을 오차가 더이상 줄어들지 않을 때까지 반복합니다.



- 나의 목표 target값과 실제 모델이 예측한 output이 얼마나 차이나는지 구한 후, 오차값을 다시 뒤로 전파해가며 변수들을 갱신하는 알고리즘. 
- Gradient Descent를 이용해 가중치 갱신을 해야 하고, Gradient Desc를 하기 위해선 Loss Function의 Gradient가 필요한데, 
그 Loss function의 gradient를 backpropagatin으로 전달 받는다. 

## 과정
- 가중치 갱신을 위해서, 필요한 loss function의 gradient를 chain Rule을 이용해 앞으로 전달해주는 알고리즘 
- 
